{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Text in Order:\n",
      "OhraO]\n",
      "OKA\n",
      "2\n",
      "ae\n",
      "ObO}\n",
      "a\n",
      "Obed\n",
      "O\n",
      "ae\n",
      "ae\n",
      "O}\n",
      "ObO}\n",
      "a\n",
      "aS\n",
      "I\n",
      "OF\n",
      "QRCODE\n",
      "VALID\n",
      "PARAMETER/DEFAULTS\n",
      "TE\n",
      "This\n",
      "label\n",
      "will\n",
      "print....-\n",
      "7?\n",
      "barcodes,\n",
      "testng\n",
      "valid\n",
      "parameters\n",
      "for\n",
      "this\n",
      "barcode.\n",
      "TEST\n",
      "INBARCODE\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "# Load your image\n",
    "image_path = '/Users/darwinye/myfile/NorthwesternU/499 Capstone/Data_subset_Final/train/images/139.bmp'\n",
    "    # '/Users/darwinye/myfile/NorthwesternU/499 Capstone/ZPL Project/ZPL Images/122.bmp'\n",
    "    \n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# upscale_factor = 2\n",
    "# image = cv2.resize(image, None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# Step 1: Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# Step 2: Apply Noise Reduction (Gaussian Blurring)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0) # Kernel size of (5, 5) and standard deviation of 0\n",
    "\n",
    "# Step 3: Apply Thresholding\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY) # Threshold value of 150\n",
    "\n",
    "# Perform OCR with PyTesseract on the thresholded image\n",
    "custom_config = r'--oem 3 --psm 6' # OCR Engine Mode 3, Page Segmentation Mode 6\n",
    "data = pytesseract.image_to_data(thresh, config=custom_config, output_type=Output.DICT)\n",
    "\n",
    "# Extract and print text in order\n",
    "text_results = []\n",
    "n_boxes = len(data['level'])\n",
    "for i in range(n_boxes):\n",
    "    (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "    text = data['text'][i]\n",
    "    if text.strip():  # Filter out empty text entries\n",
    "        text_results.append(text)\n",
    "        # Optionally, draw bounding boxes around detected text\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the results\n",
    "full_text = \"\\n\".join(text_results)\n",
    "print(\"Detected Text in Order:\")\n",
    "print(full_text)\n",
    "\n",
    "# Optional: Display the image with bounding boxes and set a timeout\n",
    "cv2.imshow(\"Detected Text\", image)\n",
    "cv2.waitKey(5000)  # Close the window after 5000 ms (5 seconds)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average OCR Confidence: 46.68%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform OCR and get confidence scores\n",
    "data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
    "confidences = [int(conf) for conf in data['conf'] if conf != '-1']  # Filter out empty detections\n",
    "\n",
    "# Calculate average confidence\n",
    "avg_confidence = sum(confidences) / len(confidences)\n",
    "print(f\"Average OCR Confidence: {avg_confidence:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Entropy: 3.17\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def text_entropy(text):\n",
    "    # Calculate character frequencies\n",
    "    frequency = Counter(text)\n",
    "    total_chars = len(text)\n",
    "\n",
    "    # Calculate entropy\n",
    "    entropy = -sum((count / total_chars) * math.log2(count / total_chars) for count in frequency.values())\n",
    "    return entropy\n",
    "\n",
    "# Use OCR output\n",
    "ocr_text = \"Detected OCR text here\"\n",
    "entropy_value = text_entropy(ocr_text)\n",
    "print(f\"Text Entropy: {entropy_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Accuracy (Dictionary Words): 50.00%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "# Load dictionary words\n",
    "english_words = set(words.words())\n",
    "ocr_words = ocr_text.split()  # Split OCR output into words\n",
    "\n",
    "# Calculate proportion of valid dictionary words\n",
    "valid_words = [word for word in ocr_words if word.lower() in english_words]\n",
    "lexical_accuracy = len(valid_words) / len(ocr_words) * 100\n",
    "print(f\"Lexical Accuracy (Dictionary Words): {lexical_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
