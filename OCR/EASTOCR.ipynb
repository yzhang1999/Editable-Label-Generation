{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darwinye/anaconda3/envs/EASTOCR/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/darwinye/anaconda3/envs/EASTOCR/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "\n",
    "# Load the frozen EAST model using OpenCV\n",
    "net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "\n",
    "# Initialize TrOCR model and processor\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darwinye/anaconda3/envs/EASTOCR/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Text in Order:\n",
      "0 1\n",
      "0 1\n",
      "QRCo\n",
      "2C O.D.E\n",
      "vali\n",
      "parame\n",
      "E. T.E.R.D.E.F.\n",
      "ehaul.\n",
      "IL T.S\n",
      "codes.\n",
      "test\n",
      "in BARC\n"
     ]
    }
   ],
   "source": [
    "# Load your image\n",
    "image_path = '/Users/darwinye/myfile/NorthwesternU/499 Capstone/Data_subset_Final/train/images/139.bmp'\n",
    "image = cv2.imread(image_path)\n",
    "orig = image.copy()\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "# Define EAST model input size\n",
    "newW, newH = (320, 320)\n",
    "rW = W / float(newW)\n",
    "rH = H / float(newH)\n",
    "\n",
    "# Resize the image and prepare it for the EAST model\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (newW, newH),\n",
    "                             (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "\n",
    "# Forward pass to get scores and geometry\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward([\"feature_fusion/Conv_7/Sigmoid\", \"feature_fusion/concat_3\"])\n",
    "\n",
    "# Decode predictions to get bounding boxes\n",
    "def decode_predictions(scores, geometry, confidence_threshold=0.5):\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    for y in range(numRows):\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        for x in range(numCols):\n",
    "            if scoresData[x] < confidence_threshold:\n",
    "                continue\n",
    "\n",
    "            offsetX, offsetY = (x * 4.0, y * 4.0)\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "    return rects, confidences\n",
    "\n",
    "# Decode bounding boxes\n",
    "rects, confidences = decode_predictions(scores, geometry)\n",
    "boxes = cv2.dnn.NMSBoxes(rects, confidences, 0.5, 0.4)\n",
    "\n",
    "# Sort boxes by position (top-to-bottom, left-to-right)\n",
    "def sort_boxes(rects):\n",
    "    y_threshold = 10  # Adjust threshold to group text rows accurately\n",
    "    sorted_indices = sorted(\n",
    "        range(len(rects)),\n",
    "        key=lambda i: (rects[i][1] // y_threshold, rects[i][0])\n",
    "    )\n",
    "    return sorted_indices\n",
    "\n",
    "# Filter overlapping boxes to reduce redundancy\n",
    "def filter_overlapping_boxes(rects, overlap_threshold=0.3):\n",
    "    filtered_boxes = []\n",
    "    for rect in rects:\n",
    "        (startX, startY, endX, endY) = rect\n",
    "        box_area = (endX - startX) * (endY - startY)\n",
    "        \n",
    "        # Check for overlap with boxes already in filtered_boxes\n",
    "        keep = True\n",
    "        for fb in filtered_boxes:\n",
    "            (fx1, fy1, fx2, fy2) = fb\n",
    "            inter_x1 = max(startX, fx1)\n",
    "            inter_y1 = max(startY, fy1)\n",
    "            inter_x2 = min(endX, fx2)\n",
    "            inter_y2 = min(endY, fy2)\n",
    "            \n",
    "            inter_w = max(0, inter_x2 - inter_x1)\n",
    "            inter_h = max(0, inter_y2 - inter_y1)\n",
    "            inter_area = inter_w * inter_h\n",
    "            \n",
    "            # Compute the IoU (intersection over union)\n",
    "            union_area = box_area + (fx2 - fx1) * (fy2 - fy1) - inter_area\n",
    "            iou = inter_area / union_area\n",
    "            \n",
    "            if iou > overlap_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "\n",
    "        if keep:\n",
    "            filtered_boxes.append(rect)\n",
    "\n",
    "    return filtered_boxes\n",
    "\n",
    "# Sort and filter the boxes\n",
    "sorted_indices = sort_boxes(rects)\n",
    "filtered_rects = filter_overlapping_boxes([rects[i] for i in sorted_indices])\n",
    "\n",
    "# Process each detected text box with TrOCR in sorted order\n",
    "text_results = []\n",
    "for rect in filtered_rects:\n",
    "    (startX, startY, endX, endY) = rect\n",
    "\n",
    "    # Scale bounding box back to original image size\n",
    "    startX = int(startX * rW)\n",
    "    startY = int(startY * rH)\n",
    "    endX = int(endX * rW)\n",
    "    endY = int(endY * rH)\n",
    "\n",
    "    # Crop the detected text region\n",
    "    cropped_img = orig[startY:endY, startX:endX]\n",
    "\n",
    "    # Convert to PIL image for TrOCR\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Recognize text using TrOCR\n",
    "    pixel_values = processor(pil_img, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    text_results.append(transcription)\n",
    "\n",
    "# Print the results in order\n",
    "full_text = \"\\n\".join(text_results)\n",
    "print(\"Detected Text in Order:\")\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EASTOCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
